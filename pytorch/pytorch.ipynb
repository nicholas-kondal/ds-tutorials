{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math, time, copy, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Tensor Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.7062e+22])\n",
      "tensor([0., 0., 0.])\n",
      "tensor([[9.2755e-39, 1.0561e-38, 7.1633e-39],\n",
      "        [9.0919e-39, 8.4490e-39, 9.6429e-39]])\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "tensor([[[[9.2755e-39, 1.0561e-38, 7.1633e-39],\n",
      "          [9.0919e-39, 8.4490e-39, 9.6429e-39]],\n",
      "\n",
      "         [[9.6429e-39, 1.0194e-38, 9.1837e-39],\n",
      "          [4.6837e-39, 9.9184e-39, 9.0000e-39]]],\n",
      "\n",
      "\n",
      "        [[[1.0561e-38, 1.0653e-38, 4.1327e-39],\n",
      "          [8.9082e-39, 9.8265e-39, 9.4592e-39]],\n",
      "\n",
      "         [[1.0561e-38, 1.0286e-38, 1.0929e-38],\n",
      "          [1.0102e-38, 4.5918e-39, 4.6837e-39]]]])\n"
     ]
    }
   ],
   "source": [
    "# Everything in pytorch is based on Tensor operations.\n",
    "# A tensor can have different dimensions so it can be 1d, 2d, or even 3d and higher (scalar, vector, matrix, tensor)\n",
    "\n",
    "# torch.empty(size): uninitiallized\n",
    "x = torch.empty(1) # scalar\n",
    "print(x)\n",
    "x = torch.empty(3) # vector, 1D\n",
    "print(x)\n",
    "x = torch.empty(2,3) # matrix, 2D\n",
    "print(x)\n",
    "x = torch.empty(2,2,3) # tensor, 3 dimensions\n",
    "print(x)\n",
    "x = torch.empty(2,2,2,3) # tensor, 4 dimensions\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3448, 0.5563, 0.6852],\n",
      "        [0.4843, 0.1852, 0.4757],\n",
      "        [0.2946, 0.2348, 0.9744],\n",
      "        [0.7820, 0.5614, 0.6313],\n",
      "        [0.2734, 0.9907, 0.0563]])\n"
     ]
    }
   ],
   "source": [
    "# torch.rand(size): random numbers [0, 1]\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]]) tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# torch.zeros(size), fill with 0\n",
    "# torch.ones(size), fill with 1\n",
    "x, y = torch.zeros(5, 3), torch.ones(5, 2)\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# check size\n",
    "print(x.size())\n",
    "\n",
    "# check data type\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], dtype=torch.float16)\n",
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "# specify types, torch.float32 default, can also do torch.int, torch.double\n",
    "x = torch.zeros(5, 3, dtype=torch.float16)\n",
    "print(x)\n",
    "\n",
    "# check type\n",
    "print(x.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000]) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# construct from data\n",
    "x = torch.tensor([5.5, 3])\n",
    "print(x, x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires_grad argument\n",
    "# This will tell pytorch that it will need to calculate the gradients for this tensor\n",
    "# later in your optimization steps\n",
    "# i.e. this is a variable in your model that you want to optimize\n",
    "x = torch.tensor([5.5, 3], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operations\n",
    "y = torch.rand(2, 2)\n",
    "x = torch.rand(2, 2)\n",
    "\n",
    "# elementwise addition\n",
    "z = x + y\n",
    "torch.add(x,y) # does same as above\n",
    "\n",
    "# in-place addition, everything with a trailing underscore is an in-place operation\n",
    "# i.e. it will modify the variable\n",
    "y.add_(x)\n",
    "\n",
    "# subtraction\n",
    "z = x - y\n",
    "z = torch.sub(x, y)\n",
    "\n",
    "# multiplication\n",
    "z = x * y\n",
    "z = torch.mul(x,y)\n",
    "y.mul_(x)\n",
    "\n",
    "# division\n",
    "z = x / y\n",
    "z = torch.div(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4553, 0.9628, 0.3184],\n",
      "        [0.1778, 0.8979, 0.0676],\n",
      "        [0.7388, 0.0814, 0.9793],\n",
      "        [0.9709, 0.9634, 0.7002],\n",
      "        [0.3897, 0.5502, 0.5409]])\n",
      "tensor([0.4553, 0.1778, 0.7388, 0.9709, 0.3897])\n",
      "tensor([0.1778, 0.8979, 0.0676])\n",
      "tensor(0.8979)\n",
      "0.8978679776191711\n"
     ]
    }
   ],
   "source": [
    "# Slicing\n",
    "x = torch.rand(5,3)\n",
    "print(x)\n",
    "print(x[:, 0]) # all rows, column 0\n",
    "print(x[1, :]) # row 1, all columns\n",
    "print(x[1,1]) # element at 1, 1\n",
    "\n",
    "# Get the actual value if only 1 element in your tensor\n",
    "print(x[1,1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# Reshape with torch.view()\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "# if -1 it pytorch will automatically determine the necessary size\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "<class 'numpy.ndarray'>\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Numpy\n",
    "# Converting a Torch Tensor to a NumPy array and vice versa is very easy\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "\n",
    "# torch to numpy with .numpy()\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "print(type(b))\n",
    "# Carful: If the Tensor is on the CPU (not the GPU),\n",
    "# both objects will share the same memory location, so changing one\n",
    "# will also change the other\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "# numpy to torch with .from_numpy(x)\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(a)\n",
    "print(b)\n",
    "# again be careful when modifying\n",
    "a += 1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default all tensors are created on the CPU,\n",
    "# but you can also move them to the GPU (only if it's available )\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    # z = z.numpy() # not possible because numpy cannot handle GPU tenors\n",
    "    # move to CPU again\n",
    "    z.to(\"cpu\")       # ``.to`` can also change dtype together!\n",
    "    # z = z.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Gradient Calculation With Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The autograd package provides automatic differentiation \n",
    "# for all operations on Tensors\n",
    "\n",
    "# requires_grad = True -> tracks all operations on the tensor. \n",
    "x = torch.randn(3, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2056, -0.4835, -1.1400], requires_grad=True)\n",
      "tensor([0.7944, 1.5165, 0.8600], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x0000021CB0C3D8C8>\n"
     ]
    }
   ],
   "source": [
    "# whenever operations are done with tensor, a computational graph is created (each operation is a node with inputs and output)\n",
    "y = x + 2\n",
    "\n",
    "# y was created as a result of an operation, so it has a grad_fn attribute.\n",
    "# grad_fn: references a Function that has created the Tensor used to calculate gradients in backpropagation\n",
    "print(x) # created by the user -> grad_fn is None\n",
    "print(y)\n",
    "print(y.grad_fn)\n",
    "\n",
    "# image below is one node of the graph after doing the first operation above - gradient function depends on the type of operation done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"autograd.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2621, 4.5994, 1.4793], grad_fn=<MulBackward0>)\n",
      "tensor(2.4469, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Do more operations on y\n",
    "z = y * y * 2\n",
    "print(z)\n",
    "z = z.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0592, 2.0220, 1.1467])\n"
     ]
    }
   ],
   "source": [
    "# Let's compute the gradients with backpropagation\n",
    "# When we finish our computation we can call .backward() and have all the gradients computed automatically.\n",
    "# The gradient for this tensor will be accumulated into .grad attribute.\n",
    "# It is the partial derivate of the function w.r.t. the tensor\n",
    "\n",
    "z.backward() # calculates dz/dx - vector-Jacobian product\n",
    "print(x.grad) # where gradients are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3143.2620, -2902.8093,   472.6248], grad_fn=<MulBackward0>)\n",
      "torch.Size([3])\n",
      "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n"
     ]
    }
   ],
   "source": [
    "# Generally speaking, torch.autograd is an engine for computing vector-Jacobian product\n",
    "# It computes partial derivates while applying the chain rule\n",
    "\n",
    "# -------------\n",
    "# Model with non-scalar output:\n",
    "# If a Tensor is non-scalar (more than 1 elements), we need to specify arguments for backward() \n",
    "# specify a gradient argument that is a tensor of matching shape.\n",
    "# needed for vector-Jacobian product\n",
    "\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "for _ in range(10):\n",
    "    y = y * 2\n",
    "\n",
    "print(y)\n",
    "print(y.shape)\n",
    "\n",
    "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float32)\n",
    "y.backward(v)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "None\n",
      "True\n",
      "<SumBackward0 object at 0x0000021CB0C3DA48>\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# -------------\n",
    "# Stop a tensor from tracking history - 3 options show below:\n",
    "# For example during our training loop when we want to update our weights\n",
    "# then this update operation should not be part of the gradient computation\n",
    "# - x.requires_grad_(False)\n",
    "# - x.detach()\n",
    "# - wrap in 'with torch.no_grad():'\n",
    "\n",
    "# .requires_grad_(...) changes an existing flag in-place.\n",
    "a = torch.randn(2, 2)\n",
    "print(a.requires_grad)\n",
    "b = ((a * 3) / (a - 1))\n",
    "print(b.grad_fn)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)\n",
    "\n",
    "# .detach(): get a new Tensor with the same content but no gradient computation:\n",
    "a = torch.randn(2, 2, requires_grad=True)\n",
    "print(a.requires_grad)\n",
    "b = a.detach()\n",
    "print(b.requires_grad)\n",
    "\n",
    "# wrap in 'with torch.no_grad():'\n",
    "a = torch.randn(2, 2, requires_grad=True)\n",
    "print(a.requires_grad)\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([0.1000, 0.1000, 0.1000, 0.1000], requires_grad=True)\n",
      "tensor(4.8000, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# -------------\n",
    "# backward() accumulates the gradient for this tensor into .grad attribute.\n",
    "# !!! We need to be careful during optimization !!!\n",
    "# Use .zero_() to empty the gradients before a new optimization step!\n",
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    # just a dummy example\n",
    "    model_output = (weights*3).sum()\n",
    "    model_output.backward()\n",
    "    \n",
    "    print(weights.grad)\n",
    "\n",
    "    # optimize model, i.e. adjust weights...\n",
    "    with torch.no_grad():\n",
    "        weights -= 0.1 * weights.grad\n",
    "\n",
    "    # this is important! It affects the final weights & output\n",
    "    weights.grad.zero_()\n",
    "\n",
    "print(weights)\n",
    "print(model_output)\n",
    "\n",
    "# Optimizer has zero_grad() method\n",
    "# optimizer = torch.optim.SGD([weights], lr=0.1)\n",
    "# During training:\n",
    "# optimizer.step()\n",
    "# optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Backpropagation Theory\n",
    "\n",
    "See Backpropagation.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "# This is the parameter we want to optimize -> requires_grad=True\n",
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "\n",
    "# forward pass to compute loss\n",
    "y_predicted = w * x\n",
    "loss = (y_predicted - y)**2\n",
    "print(loss)\n",
    "\n",
    "# backward pass to compute gradient dLoss/dw\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "\n",
    "# update weights\n",
    "# next forward and backward pass...\n",
    "\n",
    "# continue optimizing:\n",
    "# update weights, this operation should not be part of the computational graph\n",
    "with torch.no_grad():\n",
    "    w -= 0.01 * w.grad\n",
    "# don't forget to zero the gradients\n",
    "w.grad.zero_()\n",
    "\n",
    "# next forward and backward pass..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Gradient Descent With Autograd and Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch 1: w = 1.200, loss = 30.00000000\n",
      "epoch 3: w = 1.872, loss = 0.76800019\n",
      "epoch 5: w = 1.980, loss = 0.01966083\n",
      "epoch 7: w = 1.997, loss = 0.00050332\n",
      "epoch 9: w = 1.999, loss = 0.00001288\n",
      "epoch 11: w = 2.000, loss = 0.00000033\n",
      "epoch 13: w = 2.000, loss = 0.00000001\n",
      "epoch 15: w = 2.000, loss = 0.00000000\n",
      "epoch 17: w = 2.000, loss = 0.00000000\n",
      "epoch 19: w = 2.000, loss = 0.00000000\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "# Compute every step manually first\n",
    "\n",
    "'''\n",
    "General Training Pipeline Steps:\n",
    "- Prediction\n",
    "- Gradient Computation\n",
    "- Loss Computation\n",
    "- Parameter updates\n",
    "'''\n",
    "\n",
    "# Linear regression\n",
    "# f = w * x ... here, f = 2 * x\n",
    "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
    "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
    "\n",
    "w = 0.0 # same w as in f = w * x that we want to optimise\n",
    "\n",
    "# model output\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_pred):\n",
    "    return ((y_pred - y)**2).mean()\n",
    "\n",
    "# gradient\n",
    "# J = MSE = 1/N * (w*x - y)**2\n",
    "# dJ/dw = 1/N * 2x(w*x - y)\n",
    "def gradient(x, y, y_pred):\n",
    "    return np.dot(2*x, y_pred - y).mean()\n",
    "\n",
    "print(f'Prediction before training: f(5) = {forward(5):.3f}') # \n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iters = 20\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction (forward pass)\n",
    "    y_pred = forward(X)\n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    # calculate gradients\n",
    "    dw = gradient(X, Y, y_pred)\n",
    "    # update weights\n",
    "    w -= learning_rate * dw\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
    "     \n",
    "print(f'Prediction after training: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 21: w = 1.934, loss = 0.04506890\n",
      "epoch 31: w = 1.987, loss = 0.00174685\n",
      "epoch 41: w = 1.997, loss = 0.00006770\n",
      "epoch 51: w = 1.999, loss = 0.00000262\n",
      "epoch 61: w = 2.000, loss = 0.00000010\n",
      "epoch 71: w = 2.000, loss = 0.00000000\n",
      "epoch 81: w = 2.000, loss = 0.00000000\n",
      "epoch 91: w = 2.000, loss = 0.00000000\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "# Now compute every step using the tool specified\n",
    "\n",
    "'''\n",
    "General Training Pipeline Steps:\n",
    "- Prediction: PyTorch Model (needs to be designed) - done in section 5\n",
    "- Gradient Computation: Autograd (automatic backpropagation algorithm) - done below\n",
    "- Loss Computation: PyTorch Loss class (needs to be selected) - done in section 5\n",
    "- Parameter updates: PyTorch Optimiser class (needs to be selected) - done in section 5\n",
    "'''\n",
    "\n",
    "# Here we replace the manually computed gradient with autograd\n",
    "\n",
    "# Linear regression\n",
    "# f = w * x \n",
    "\n",
    "# here : f = 2 * x\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# model output\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_pred):\n",
    "    return ((y_pred - y)**2).mean()\n",
    "\n",
    "print(f'Prediction before training: f(5) = {forward(5).item():.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction (forward pass)\n",
    "    y_pred = forward(X)\n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    # calculate gradients = backward pass\n",
    "    l.backward()\n",
    "    # update weights: w.data = w.data - learning_rate * w.grad\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "    # zero the gradients after updating\n",
    "    w.grad.zero_()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.8f}')\n",
    "\n",
    "print(f'Prediction after training: f(5) = {forward(5).item():.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Training Pipeline: Model, Loss, and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch  1 : w =  tensor(0.3000, requires_grad=True)  loss =  tensor(30., grad_fn=<MseLossBackward0>)\n",
      "epoch  11 : w =  tensor(1.6653, requires_grad=True)  loss =  tensor(1.1628, grad_fn=<MseLossBackward0>)\n",
      "epoch  21 : w =  tensor(1.9341, requires_grad=True)  loss =  tensor(0.0451, grad_fn=<MseLossBackward0>)\n",
      "epoch  31 : w =  tensor(1.9870, requires_grad=True)  loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch  41 : w =  tensor(1.9974, requires_grad=True)  loss =  tensor(6.7705e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch  51 : w =  tensor(1.9995, requires_grad=True)  loss =  tensor(2.6244e-06, grad_fn=<MseLossBackward0>)\n",
      "epoch  61 : w =  tensor(1.9999, requires_grad=True)  loss =  tensor(1.0176e-07, grad_fn=<MseLossBackward0>)\n",
      "epoch  71 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(3.9742e-09, grad_fn=<MseLossBackward0>)\n",
      "epoch  81 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(1.4670e-10, grad_fn=<MseLossBackward0>)\n",
      "epoch  91 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(5.0768e-12, grad_fn=<MseLossBackward0>)\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "General Training Pipeline Steps:\n",
    "- Prediction: PyTorch Model (needs to be designed) - done below\n",
    "- Gradient Computation: Autograd (automatic backpropagation algorithm)\n",
    "- Loss Computation: PyTorch Loss class (needs to be selected) - done here\n",
    "- Parameter updates: PyTorch Optimiser class (needs to be selected) - done here\n",
    "'''\n",
    "\n",
    "# 1) Design model (input, output size, forward pass with different layers)\n",
    "# 2) Construct loss and optimizer\n",
    "# 3) Training loop\n",
    "#       - Forward = compute prediction and loss\n",
    "#       - Backward = compute gradients\n",
    "#       - Update weights\n",
    "\n",
    "# Linear regression\n",
    "# f = w * x \n",
    "\n",
    "# here : f = 2 * x\n",
    "\n",
    "# 0) Training samples\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "\n",
    "# 1) Design Model: Weights to optimize and forward function\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "print(f'Prediction before training: f(5) = {forward(5).item():.3f}')\n",
    "\n",
    "# 2) Define loss and optimizer\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "# callable function\n",
    "loss = nn.MSELoss() # mean squared error\n",
    "\n",
    "optimizer = torch.optim.SGD([w], lr=learning_rate)\n",
    "\n",
    "# 3) Training loop\n",
    "for epoch in range(n_iters):\n",
    "    # predict = forward pass\n",
    "    y_predicted = forward(X)\n",
    "    # loss\n",
    "    l = loss(Y, y_predicted)\n",
    "    # calculate gradients = backward pass\n",
    "    l.backward()\n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "    # zero the gradients after updating\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch ', epoch+1, ': w = ', w, ' loss = ', l)\n",
    "\n",
    "print(f'Prediction after training: f(5) = {forward(5).item():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#samples: 4, #features: 1\n",
      "Prediction before training: f(5) = -3.231\n",
      "epoch  1 : w =  -0.28043633699417114  loss =  tensor(51.7713, grad_fn=<MseLossBackward0>)\n",
      "epoch  11 : w =  1.3744432926177979  loss =  tensor(1.4753, grad_fn=<MseLossBackward0>)\n",
      "epoch  21 : w =  1.648272156715393  loss =  tensor(0.1661, grad_fn=<MseLossBackward0>)\n",
      "epoch  31 : w =  1.6997346878051758  loss =  tensor(0.1248, grad_fn=<MseLossBackward0>)\n",
      "epoch  41 : w =  1.7152106761932373  loss =  tensor(0.1167, grad_fn=<MseLossBackward0>)\n",
      "epoch  51 : w =  1.724685788154602  loss =  tensor(0.1099, grad_fn=<MseLossBackward0>)\n",
      "epoch  61 : w =  1.7329891920089722  loss =  tensor(0.1035, grad_fn=<MseLossBackward0>)\n",
      "epoch  71 : w =  1.7409038543701172  loss =  tensor(0.0975, grad_fn=<MseLossBackward0>)\n",
      "epoch  81 : w =  1.7485616207122803  loss =  tensor(0.0918, grad_fn=<MseLossBackward0>)\n",
      "epoch  91 : w =  1.7559895515441895  loss =  tensor(0.0865, grad_fn=<MseLossBackward0>)\n",
      "Prediction after training: f(5) = 9.511\n"
     ]
    }
   ],
   "source": [
    "# 0) Training samples, watch the shape!\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32) # both are 2D arrays\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "print(f'#samples: {n_samples}, #features: {n_features}')\n",
    "# 0) create a test sample\n",
    "X_test = torch.tensor([5], dtype=torch.float32)\n",
    "\n",
    "# 1) Design Model, the model has to implement the forward pass!\n",
    "# Here we can use a built-in model from PyTorch\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "# we can call this model with samples X\n",
    "model = nn.Linear(input_size, output_size) # linear model knows we want to optimise 'w' in f=wx\n",
    "\n",
    "# to write custom model, need to extend nn.Module and define __init__, forward()... below does same as above\n",
    "'''\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        # define diferent layers\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "\n",
    "model = LinearRegression(input_size, output_size)\n",
    "'''\n",
    "\n",
    "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
    "\n",
    "# 2) Define loss and optimizer\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) Training loop\n",
    "for epoch in range(n_iters):\n",
    "    # predict = forward pass with our model\n",
    "    y_predicted = model(X)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y, y_predicted)\n",
    "\n",
    "    # calculate gradients = backward pass\n",
    "    l.backward()\n",
    "\n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero the gradients after updating\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        [w, b] = model.parameters() # unpack parameters (weight and bias)\n",
    "        print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l)\n",
    "\n",
    "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss = 3962.6675\n",
      "epoch: 20, loss = 2794.5825\n",
      "epoch: 30, loss = 1998.3729\n",
      "epoch: 40, loss = 1455.5300\n",
      "epoch: 50, loss = 1085.3508\n",
      "epoch: 60, loss = 832.8633\n",
      "epoch: 70, loss = 660.6152\n",
      "epoch: 80, loss = 543.0830\n",
      "epoch: 90, loss = 462.8705\n",
      "epoch: 100, loss = 408.1176\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0) Prepare data\n",
    "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=4) \n",
    "# cast to float Tensor\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32)) # converting from double to float (double will cause errors (apparently))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "y = y.view(y.shape[0], 1) # reshape to 1 column (view is built-in Python method to reshape)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# 1) Model\n",
    "# Linear model f = wx + b\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# 2) Loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# 3) Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass and loss\n",
    "    y_predicted = model(X)\n",
    "    loss = criterion(y_predicted, y)\n",
    "    # Backward pass and update weights\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # zero grad before new step\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
    "\n",
    "# Plot\n",
    "predicted = model(X).detach().numpy() # detach creates new tensor and takes operation out of computational graph (so no gradient calculations)\n",
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "plt.plot(X_numpy, predicted, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss = 0.4870\n",
      "epoch: 20, loss = 0.4153\n",
      "epoch: 30, loss = 0.3670\n",
      "epoch: 40, loss = 0.3319\n",
      "epoch: 50, loss = 0.3051\n",
      "epoch: 60, loss = 0.2838\n",
      "epoch: 70, loss = 0.2665\n",
      "epoch: 80, loss = 0.2520\n",
      "epoch: 90, loss = 0.2397\n",
      "epoch: 100, loss = 0.2291\n",
      "accuracy: 0.8947\n"
     ]
    }
   ],
   "source": [
    "# 0) Prepare data\n",
    "bc = datasets.load_breast_cancer() # binary classification\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "# scale\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "# 1) Model\n",
    "# Linear model f = wx + b , sigmoid at the end\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "\n",
    "model = LogisticRegression(n_features)\n",
    "\n",
    "# 2) Loss and optimizer\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss() # binary cross-entropy loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass and loss\n",
    "    y_pred = model(X_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    # Backward pass and update\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # zero grad before new step\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
    "\n",
    "# Evaluation\n",
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test)\n",
    "    y_predicted_cls = y_predicted.round() # converting to 0 or 1\n",
    "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0]) # add 1 for every correct prediction then divide by number of all labels\n",
    "    print(f'accuracy: {acc.item():.4f}') # can improve by tuning learning rate, number of epochs, optimiser type etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 - Dataset and DataLoader Batch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# training loop\\nfor epoch in range(num_epochs):\\n    # loop over all batches\\n    for i in range(total_batches):\\n        batch_x, batch_y = ...\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gradient computation etc. not efficient for whole data set\n",
    "# -> divide dataset into small batches\n",
    "\n",
    "'''\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # loop over all batches\n",
    "    for i in range(total_batches):\n",
    "        batch_x, batch_y = ...\n",
    "'''\n",
    "\n",
    "# epoch = one forward and backward pass of ALL training samples\n",
    "# batch_size = number of training samples used in one forward/backward pass\n",
    "# number of iterations = number of passes, each pass (forward+backward) using [batch_size] number of sampes\n",
    "# e.g : 100 samples, batch_size=20 -> 100/20=5 iterations for 1 epoch\n",
    "\n",
    "# --> DataLoader can do the batch computation for us\n",
    "\n",
    "# Implement a custom Dataset:\n",
    "# inherit Dataset\n",
    "# implement __init__ , __getitem__ , and __len__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wine csv has 1 of 3 class labels in first column, several features in others\n",
    "class WineDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        # Initialize data, download, etc.\n",
    "        # read with numpy or pandas\n",
    "        xy = np.loadtxt('pytorch_batch_wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.n_samples = xy.shape[0]\n",
    "\n",
    "        # here the first column is the class label, the rest are the features\n",
    "        self.x_data = torch.from_numpy(xy[:, 1:]) # size [n_samples, n_features]\n",
    "        self.y_data = torch.from_numpy(xy[:, [0]]) # size [n_samples, 1]\n",
    "\n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index] # returns tuple\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "# create dataset\n",
    "dataset = WineDataset()\n",
    "\n",
    "# get first sample and unpack\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2430e+01, 1.5300e+00, 2.2900e+00, 2.1500e+01, 8.6000e+01, 2.7400e+00,\n",
      "         3.1500e+00, 3.9000e-01, 1.7700e+00, 3.9400e+00, 6.9000e-01, 2.8400e+00,\n",
      "         3.5200e+02],\n",
      "        [1.3730e+01, 1.5000e+00, 2.7000e+00, 2.2500e+01, 1.0100e+02, 3.0000e+00,\n",
      "         3.2500e+00, 2.9000e-01, 2.3800e+00, 5.7000e+00, 1.1900e+00, 2.7100e+00,\n",
      "         1.2850e+03],\n",
      "        [1.3730e+01, 4.3600e+00, 2.2600e+00, 2.2500e+01, 8.8000e+01, 1.2800e+00,\n",
      "         4.7000e-01, 5.2000e-01, 1.1500e+00, 6.6200e+00, 7.8000e-01, 1.7500e+00,\n",
      "         5.2000e+02],\n",
      "        [1.3030e+01, 9.0000e-01, 1.7100e+00, 1.6000e+01, 8.6000e+01, 1.9500e+00,\n",
      "         2.0300e+00, 2.4000e-01, 1.4600e+00, 4.6000e+00, 1.1900e+00, 2.4800e+00,\n",
      "         3.9200e+02]]) tensor([[2.],\n",
      "        [1.],\n",
      "        [3.],\n",
      "        [2.]])\n"
     ]
    }
   ],
   "source": [
    "# Load whole dataset with DataLoader\n",
    "# shuffle: shuffle data, good for training\n",
    "# num_workers: faster loading with multiple subprocesses\n",
    "# !!! IF YOU GET AN ERROR DURING LOADING, SET num_workers TO 0 !!!\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=0) # num_workers for parallel processing\n",
    "\n",
    "# convert to an iterator and look at one random sample\n",
    "dataiter = iter(train_loader)\n",
    "data = dataiter.next()\n",
    "features, labels = data\n",
    "print(features, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 45\n",
      "Epoch: 1/2, Step 5/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 10/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 15/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 20/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 25/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 30/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 35/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 40/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 45/45| Inputs torch.Size([2, 13]) | Labels torch.Size([2, 1])\n",
      "Epoch: 2/2, Step 5/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 10/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 15/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 20/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 25/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 30/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 35/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 40/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 45/45| Inputs torch.Size([2, 13]) | Labels torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "# Dummy Training loop\n",
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4) # 4 is batch_size\n",
    "print(total_samples, n_iterations)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # here: 178 samples, batch_size = 4, n_iters=178/4=44.5 -> 45 iterations\n",
    "        # Run your training process (dummy results printed below)\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9913344it [00:01, 6933692.42it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29696it [00:00, 14829628.72it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1649664it [00:00, 2714956.81it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5120it [00:00, 5114273.99it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "torch.Size([3, 1, 28, 28]) torch.Size([3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# some famous datasets are available in torchvision.datasets\n",
    "# e.g. MNIST, Fashion-MNIST, CIFAR10, COCO\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=torchvision.transforms.ToTensor(), download=True) # transform argument applys transformer specified\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=3, shuffle=True)\n",
    "\n",
    "# look at one random sample\n",
    "dataiter = iter(train_loader)\n",
    "data = dataiter.next()\n",
    "inputs, targets = data\n",
    "print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 - Dataset Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTransforms can be applied to PIL images, tensors, ndarrays, or custom data\\nduring creation of the DataSet\\n\\ncomplete list of built-in transforms: \\nhttps://pytorch.org/docs/stable/torchvision/transforms.html\\n\\nOn Images\\n---------\\nCenterCrop, Grayscale, Pad, RandomAffine\\nRandomCrop, RandomHorizontalFlip, RandomRotation\\nResize, Scale\\n\\nOn Tensors\\n----------\\nLinearTransformation, Normalize, RandomErasing\\n\\nConversion\\n----------\\nToPILImage: from tensor or ndrarray\\nToTensor : from numpy.ndarray or PILImage\\n\\nGeneric\\n-------\\nUse Lambda \\n\\nCustom\\n------\\nWrite own class\\n\\nCompose multiple Transforms\\n---------------------------\\ncomposed = transforms.Compose([Rescale(256),\\n                               RandomCrop(224)])\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "\n",
    "'''\n",
    "Transforms can be applied to PIL images, tensors, ndarrays, or custom data\n",
    "during creation of the DataSet\n",
    "\n",
    "complete list of built-in transforms: \n",
    "https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "\n",
    "On Images\n",
    "---------\n",
    "CenterCrop, Grayscale, Pad, RandomAffine\n",
    "RandomCrop, RandomHorizontalFlip, RandomRotation\n",
    "Resize, Scale\n",
    "\n",
    "On Tensors\n",
    "----------\n",
    "LinearTransformation, Normalize, RandomErasing\n",
    "\n",
    "Conversion\n",
    "----------\n",
    "ToPILImage: from tensor or ndrarray\n",
    "ToTensor : from numpy.ndarray or PILImage\n",
    "\n",
    "Generic\n",
    "-------\n",
    "Use Lambda \n",
    "\n",
    "Custom\n",
    "------\n",
    "Write own class\n",
    "\n",
    "Compose multiple Transforms\n",
    "---------------------------\n",
    "composed = transforms.Compose([Rescale(256), RandomCrop(224)])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same class as before\n",
    "class WineDataset(Dataset):\n",
    "\n",
    "    def __init__(self, transform=None):\n",
    "        xy = np.loadtxt('pytorch_batch_wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.n_samples = xy.shape[0]\n",
    "        # note that we do not convert to tensor here\n",
    "        self.x_data = xy[:, 1:]\n",
    "        self.y_data = xy[:, [0]]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x_data[index], self.y_data[index]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Transforms\n",
    "# implement __call__(self, sample)\n",
    "class ToTensor:\n",
    "    # Convert ndarrays to Tensors\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "\n",
    "class MulTransform:\n",
    "    # multiply inputs with a given factor\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Transform\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03] [1.]\n"
     ]
    }
   ],
   "source": [
    "print('Without Transform')\n",
    "dataset = WineDataset()\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With Tensor Transform\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "print('\\nWith Tensor Transform')\n",
    "dataset = WineDataset(transform=ToTensor()) # transform = None will result in same as above\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With Tensor and Multiplication Transform\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "tensor([5.6920e+01, 6.8400e+00, 9.7200e+00, 6.2400e+01, 5.0800e+02, 1.1200e+01,\n",
      "        1.2240e+01, 1.1200e+00, 9.1600e+00, 2.2560e+01, 4.1600e+00, 1.5680e+01,\n",
      "        4.2600e+03]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "print('\\nWith Tensor and Multiplication Transform')\n",
    "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n",
    "dataset = WineDataset(transform=composed)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 - Softmax and Cross-Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax formula applies exp to each element and normalises it by dividing by sum of all exp's - output is between 0 and 1 (probabilities), larger value = larger probability, sum of probabilities is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./softmax.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class with highest probability is chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./softmax_layer.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#        -> 2.0              -> 0.65  \n",
    "# Linear -> 1.0  -> Softmax  -> 0.25   -> CrossEntropy(y, y_hat)\n",
    "#        -> 0.1              -> 0.1                   \n",
    "#\n",
    "#     scores(logits)      probabilities\n",
    "#                           sum = 1.0\n",
    "#\n",
    "\n",
    "# Softmax applies the exponential function to each element, and normalizes\n",
    "# by dividing by the sum of all these exponentials\n",
    "# -> squashes the output to be between 0 and 1 = probability\n",
    "# sum of all probabilities is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax numpy: [0.65900114 0.24243297 0.09856589]\n",
      "softmax torch: tensor([0.6590, 0.2424, 0.0986])\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "x = np.array([2.0, 1.0, 0.1])\n",
    "outputs = softmax(x)\n",
    "print('softmax numpy:', outputs)\n",
    "\n",
    "x = torch.tensor([2.0, 1.0, 0.1])\n",
    "outputs = torch.softmax(x, dim=0) # along values along first axis\n",
    "print('softmax torch:', outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-entropy loss measures performance of classification model whose output is a probability bewtween 0 and 1, can be used in multi-class classification too\n",
    "\n",
    "Loss increases as predicted probability diverges from actual label (better prediction = lower loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./crossentropy.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross entropy\n",
    "# Cross-entropy loss, or log loss, measures the performance of a classification model \n",
    "# whose output is a probability value between 0 and 1. \n",
    "# -> loss increases as the predicted probability diverges from the actual label\n",
    "def cross_entropy(actual, predicted):\n",
    "    EPS = 1e-15\n",
    "    predicted = np.clip(predicted, EPS, 1 - EPS)\n",
    "    loss = -np.sum(actual * np.log(predicted))\n",
    "    return loss # / float(predicted.shape[0]) - for normalising if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss1 numpy: 0.3567\n",
      "Loss2 numpy: 2.3026\n"
     ]
    }
   ],
   "source": [
    "# y must be one hot encoded\n",
    "# if class 0: [1 0 0]\n",
    "# if class 1: [0 1 0]\n",
    "# if class 2: [0 0 1]\n",
    "Y = np.array([1, 0, 0])\n",
    "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
    "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
    "l1 = cross_entropy(Y, Y_pred_good)\n",
    "l2 = cross_entropy(Y, Y_pred_bad)\n",
    "print(f'Loss1 numpy: {l1:.4f}')\n",
    "print(f'Loss2 numpy: {l2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Loss1: 0.4170\n",
      "PyTorch Loss2: 1.8406\n",
      "Actual class: 0, Y_pred1: 0, Y_pred2: 1\n"
     ]
    }
   ],
   "source": [
    "# CrossEntropyLoss in PyTorch (applies Softmax)\n",
    "# nn.CrossEntropyLoss applies the formula nn.LogSoftmax + nn.NLLLoss (NLLLoss = negative log likelihood loss) -> we shouldn't implement softmax ourselves\n",
    "loss = nn.CrossEntropyLoss()\n",
    "# loss(input, target)\n",
    "\n",
    "# target is of size nSamples = 1\n",
    "# each element has class label: 0, 1, or 2\n",
    "# Y (=target) contains class labels, not one-hot\n",
    "Y = torch.tensor([0])\n",
    "\n",
    "# input is of size nSamples x nClasses = 1 x 3\n",
    "# y_pred (=input) must be raw, unnormalizes scores (logits) for each class, not softmax\n",
    "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
    "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "\n",
    "print(f'PyTorch Loss1: {l1.item():.4f}')\n",
    "print(f'PyTorch Loss2: {l2.item():.4f}')\n",
    "\n",
    "# get predictions\n",
    "_, predictions1 = torch.max(Y_pred_good, 1) # choose highest value i.e. 2.0 at index 0\n",
    "_, predictions2 = torch.max(Y_pred_bad, 1) # # choose highest value i.e. 2.0 at index 1\n",
    "print(f'Actual class: {Y.item()}, Y_pred1: {predictions1.item()}, Y_pred2: {predictions2.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss1:  0.2834\n",
      "Batch Loss2: 1.6418\n",
      "Actual class: tensor([2, 0, 1]), Y_pred1: tensor([2, 0, 1]), Y_pred2: tensor([0, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "# allows batch loss for multiple samples\n",
    "\n",
    "# target is of size nBatch = 3\n",
    "# each element has class label: 0, 1, or 2\n",
    "Y = torch.tensor([2, 0, 1])\n",
    "\n",
    "# input is of size nBatch x nClasses = 3 x 3\n",
    "# Y_pred are logits (not softmax)\n",
    "Y_pred_good = torch.tensor(\n",
    "    [[0.1, 0.2, 3.9], # predict class 2\n",
    "    [1.2, 0.1, 0.3], # predict class 0\n",
    "    [0.3, 2.2, 0.2]]) # predict class 1\n",
    "\n",
    "Y_pred_bad = torch.tensor(\n",
    "    [[0.9, 0.2, 0.1],\n",
    "    [0.1, 0.3, 1.5],\n",
    "    [1.2, 0.2, 0.5]])\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "print(f'Batch Loss1:  {l1.item():.4f}')\n",
    "print(f'Batch Loss2: {l2.item():.4f}')\n",
    "\n",
    "# get predictions\n",
    "_, predictions1 = torch.max(Y_pred_good, 1)\n",
    "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
    "print(f'Actual class: {Y}, Y_pred1: {predictions1}, Y_pred2: {predictions2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary and multiclass NNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./softmax_nn_binary.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./softmax_nn_multi.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification\n",
    "class NeuralNet1(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet1, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        # sigmoid at the end\n",
    "        y_pred = torch.sigmoid(out)\n",
    "        return y_pred\n",
    "\n",
    "model = NeuralNet1(input_size=28*28, hidden_size=5)\n",
    "criterion = nn.BCELoss() # binary cross-entropy loss\n",
    "\n",
    "# Multiclass problem\n",
    "class NeuralNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU() # activation function\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        # no softmax at the end\n",
    "        return out\n",
    "\n",
    "model = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n",
    "criterion = nn.CrossEntropyLoss()  # (applies Softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 - Activation functions\n",
    "\n",
    "See ActivationFunctions.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn.ReLU() creates an nn.Module which you can add e.g. to an nn.Sequential model.\n",
    "#torch.relu on the other side is just the functional API call to the relu function,\n",
    "#so that you can add it e.g. in your forward method yourself.\n",
    "\n",
    "# can also use F.relu, F.leaky_relu (leaky not available in nn but is in functional)\n",
    "\n",
    "# option 1 (create nn modules)\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "# option 2 (use activation functions directly in forward pass)\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.linear1(x))\n",
    "        out = torch.sigmoid(self.linear2(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0120, 0.0889, 0.2418, 0.6572])\n",
      "tensor([0.0120, 0.0889, 0.2418, 0.6572])\n",
      "tensor([0.2689, 0.7311, 0.8808, 0.9526])\n",
      "tensor([0.2689, 0.7311, 0.8808, 0.9526])\n",
      "tensor([-0.7616,  0.7616,  0.9640,  0.9951])\n",
      "tensor([-0.7616,  0.7616,  0.9640,  0.9951])\n",
      "tensor([0., 1., 2., 3.])\n",
      "tensor([0., 1., 2., 3.])\n",
      "tensor([-0.0100,  1.0000,  2.0000,  3.0000])\n",
      "tensor([-0.0100,  1.0000,  2.0000,  3.0000])\n"
     ]
    }
   ],
   "source": [
    "# output = w*x + b\n",
    "# output = activation_function(output)\n",
    "\n",
    "x = torch.tensor([-1.0, 1.0, 2.0, 3.0])\n",
    "\n",
    "# sofmax\n",
    "output = torch.softmax(x, dim=0)\n",
    "print(output)\n",
    "sm = nn.Softmax(dim=0)\n",
    "output = sm(x)\n",
    "print(output)\n",
    "\n",
    "# sigmoid \n",
    "output = torch.sigmoid(x)\n",
    "print(output)\n",
    "s = nn.Sigmoid()\n",
    "output = s(x)\n",
    "print(output)\n",
    "\n",
    "#tanh\n",
    "output = torch.tanh(x)\n",
    "print(output)\n",
    "t = nn.Tanh()\n",
    "output = t(x)\n",
    "print(output)\n",
    "\n",
    "# relu\n",
    "output = torch.relu(x)\n",
    "print(output)\n",
    "relu = nn.ReLU()\n",
    "output = relu(x)\n",
    "print(output)\n",
    "\n",
    "# leaky relu - helps solve vanishing gradient problem (with normal relu, gradients for nodes with negative inputs would just be 0 since their final values would be changed to 0 by relu - weights don't get updated, results in \"dead\" neurons that won't learn anything)\n",
    "output = F.leaky_relu(x)\n",
    "print(output)\n",
    "lrelu = nn.LeakyReLU()\n",
    "output = lrelu(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEWCAYAAABmE+CbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyZklEQVR4nO3dfXxcZ3ng/d+lV8uWRGQ5khJJiewgmcgCJYoWoaLHzkLYBhpeH15KQ5aHh9ZLCxS2pZSQLi9tWWjzlAKFLa9tnpIQYEvTLgklOMQvERUKshwRy4nlYHmxlFhqLBNJli1Lo2v/ODMTxZGt2849PudWru/nMx9prBnplznR3Jo559y3qCrGGGNMXtwBxhhjksEGBGOMMYANCMYYY9JsQDDGGAPYgGCMMSbNBgRjjDGADQjGBENEBkXk2rg7zMplA4JJNBGZXnRZEJETi67feJ7f8/8Rke4l/v2QiFx3hvt8QkTmTuv58Pn8fMfG20Tkzxf/m6puUtUdufqZxhTEHWDM2ahqaeZzETkE/Laq3hdTzndU9R0x/Wxjcs5eIZggichLRaRHRH4lIk+IyBdFpGjR11VE3iMiB0TkmIh8SUQkBx2fEJHbF11vSP/sgvT1HSLyZyLyExGZEpEfici6RbfvEpF/S/93HE6/etkK3Ah8OP1K5Pvp22ZfwYhIsYh8TkQeT18+JyLF6a9dKyIjIvKHIjKefnze5fu/3aw8NiCYUKWA/wqsAzqBVwK/d9ptbgD+A9AKvBX49QsZuMhvAe8CqoAi4EMAInIZ8K/A3wAXA1cBD6nqV4E7gL9U1VJVfe0S3/MW4GXp+7QCLwX+ZNHXa4AXALXAu4EviUiF7/8ws7LYgGCCpKq7VfWnqjqvqoeArwBbTrvZZ1T1V6r6S2A70ZNnxsvSf5VnL8Bly/zYt552n0sdc/9eVYdU9QTw3UUdNwL3qeqdqjqnqkdV9SHH73kj8KeqOq6q/w58Erhp0dfn0l+fU9UfANPARsfvbZ6nbB+CCZKINAGfBdqB1UT/L+8+7WZHFn0+A5Quuv5TVe067XseWubHfvf0fQiO70KdqaMe+IXLN1jCpcD/XnT9f6f/LeOoqs6f4ecasyR7hWBC9bfAo0CjqpYDHwW87yNwcJxoQMqoOYf7HgauOMPXlpuG+HHg8kXXL0v/mzHnzQYEE6oyYBKYFpEXAb8bU8dDwGYRuUxEXgDcfA73vQO4TkTeKiIFIlIpIlelvzYGbDjLfe8E/kRELk7vpP4YcPtZbm/MsmxAMKH6ENHO2inga8B34ohQ1W3pn/1zores7j6H+/4SeA3wh8AE0eDSmv7yN4Dm9L6Kf17i7n8O9KV/7sNAf/rfjDlvYgvkGGOMAXuFYIwxJi32AUFE8kVkj4g4v9Q2xhjjX+wDAvAB4JG4I4wx5vku1gFBROqA3wC+HmeHMcaY+E9M+xzwYaJDCJeUntdlK0BJSck19fX1ABQXF5Ofn8/MzAwABQUFlJSUMDU1lbkfpaWlzMzMkEqlAFizZg1zc3OcOnUKgFWrViEinDhxAoDCwkKKi4uZnp4GIC8vjzVr1pzz9xCR7Ncz3+P48eMsLCwAUFpayuzsLHNzc6T/u1BVTp48CUBRURGFhYUcP34cgPz8fFavXu3le0xPT5M5kKCoqIiFhQXm56Pzl1avXk0qlWJ2dtbpMQYoKyvjxIkT5/09XLZTfn4+RUVF3rfTUt/jfB9jVaWgoCAn2+m5PsaLv8fc3BwikpPt5PP3aWZmBhHxvp0WP8Y+vsfk5GT25ESf28n379OePXueVNWLWY6qxnIhmmfmf6Q/vxa4e7n7NDU1aQi2b98ed4IT6/QnhEZV6/QtlE6gTx2el+N8y+jlwOvS0wV8G3jF4lkjl7J69eqzfTkxWltbl79RAlinPyE0gnX6Fkqnq9gGBFW9WVXrVLUB+E3gfl1mrvnMS6CkW/wSMMms058QGsE6fQul01USjjJylnkfLekOHjwYd4IT6/QnhEawTt9C6XQV905lADRaFnBHzBnGGPO8FtQrhOLi4rgTnDQ0NMSd4MQ6/QmhEazTt1A6XQU1IOTn58ed4GTt2rVxJzixTn9CaATr9C2UTldBDQiZY2+Trr+/P+4EJ9bpTwiNYJ2+hdLpKqgBwRhjTO4ENSAUFCRiH/iyKirCWMvcOv0JoRGs07dQOl0FtR5Ce3u79vX1xZ1hjDFBEZHdqtq+3O2CeoUQykkgO3fujDvBiXX6E0IjWKdvoXS6CmpACEUor7qs058QGsE6fQul05UNCDmQmf0w6azTnxAawTp9C6XTle1DMMaYFW5F7kPIzLOedAMDA3EnOLFOf0JoBOv0LZROV0ENCJlFI5Lu2LFjcSc4sU5/QmgE6/QtlE5XQQ0IxhhjcieofQhXX3217tmzJ+6MZU1OTlJeXh53xrKs058QGsE6fQulc0XuQwhlgZyJiYm4E5xYpz8hNIJ1+hZKp6ugBoRQFsg5dOhQ3AlOrNOfEBrBOn0LpdNVUAOCMcaY3AlqQAhlgZwNGzbEneDEOv0JoRGs07dQOl3FNiCIyCoReVBEBkRkUEQ+udx9Qlkgp6ysLO4EJ9bpTwiNYJ2+hdLpKs5XCLPAK1S1FbgKuF5EXna2O4SyQE4oJ6tYpz8hNIJ1+hZKp6vYFhjQ6HjX6fTVwvQlnGNgjTFmhYl1H4KI5IvIQ8A4sE1Ve892+1AWyKmsrIw7wYl1+hNCI1inb6F0ukrEiWkichFwF/B+Vd172te2AlsBLr300mvuuOMOINqZU1ZWln3JVllZyaZNm9i1axcQDR5dXV309/czOTkJQHt7O2NjYxw+fBiAxsZGiouL2bs3+pFVVVU0NTXR3d0NRDuxOzs76evrY3o6ejHT0dHByMgIo6OjAGzcuJH8/Hz27dsHQE1NDZdffjm9vdHYVlJSQkdHB729vdm5mDo7OxkeHubIkSMANDc3k0ql2L9/PwC1tbXU1dVlv0dpaSnt7e309PRkD73t6upiaGiI8fFxAFpaWpidneXAgQMA1NfXU11dTWYywPLyctra2uju7s5OAdLV1cUjjzzC0aNHAWhtbWVqaoqDBw8C0NDQwNq1a7PrxlZUVNDa2srOnTtRVUSELVu2MDAwkD2Fv62tjYmJiezheD620xVXXEFJSYn37bR+/Xp6enoSv502b97M4OBg4rdTrn6fkrydHnjggez5UUneTmVlZU4npqGqibgAHwc+dLbbNDU1aQi2b98ed4IT6/QnhEZV6/QtlE6gTx2eh+M8yuji9CsDRKQEuA54NK4eY4x5vovzTflLgP9fRPKJ9mV8V1XvPtsdQlmMIpR9HdbpTwiNYJ2+hdLpKhH7EFzZAjnGGHPuVuTkdqGch5DZaZR01ulPCI1gnb6F0ukqqAEhlNlOM3v3k846/QmhEazTt1A6XQU1IBhjjMmdoPYhtLW1aQgv0aanpyktLY07Y1nW6U8IjWCdvoXSuSL3IczNzcWd4GRsbCzuBCfW6U8IjWCdvoXS6SqoAeHUqVNxJzjJnLmZdNbpTwiNYJ2+hdLpKqgBwRhjTO4ENSCsWrUq7gQnjY2NcSc4sU5/QmgE6/QtlE5XQQ0IoZypHMrKbtbpTwiNYJ2+hdLpKqgBITO7YdJlZntMOuv0J4RGsE7fQul0FdSAYIwxJneCGhAKCwvjTnBSVVUVd4IT6/QnhEawTt9C6XQV1Ilp11xzje7evTvujGXNz88HMQuidfoTQiNYp2+hdK7IE9MyqywlXWaFqKSzTn9CaATr9C2UTldBDQjGGGNyJ6gBIS8vjNxQDkWzTn9CaATr9C2UTldB7UOwBXKMMebcrch9CKEskBPKoGWd/oTQCNbpWyidroIaEEJZICeUnd/W6U8IjWCdvoXS6Sq2AUFE6kVku4g8IiKDIvKBuFqMMcbEuA9BRC4BLlHVfhEpA3YDb1DVfWe6TygL5Jw4cYKSkpK4M5Zlnf6E0AjW6VsonYnfh6CqT6hqf/rzKeARoPZs9wllgZyRkZG4E5xYpz8hNIJ1+hZKp6tEnGInIg3A1UDvEl/bCmyF6DTxHTt2ALBhwwbKysoYGBgAoLKykk2bNrFr1y4ACgoK6Orqor+/P7sQdnt7O2NjY9lFLRobGykuLs5OUFVVVUVTU1P2ZJPi4mI6Ozvp6+vLvlfY0dHByMgIo6OjAGzcuJH8/Hz27Yte2NTU1PD4449nv15SUkJHRwe9vb3Zyfk6OzsZHh7myJEjADQ3N5NKpdi/fz8AtbW11NXV0dsbPRylpaW0t7fT09PD7OwsAF1dXQwNDTE+Pg5AS0sLs7OzHDhwAID6+nqqq6uzO73Ky8tpa2uju7ub+fl5AFSVkydPcvToUQBaW1uZmpri4MGDADQ0NLB27Voyr8oqKipobW1l586dqCoiwpYtWxgYGODYsWMAtLW1MTExwaFDh7xtp1OnTlFRUeF9O61fv56enh4v22l6epqnnnoqJ9tp8+bNDA4OetlOhw8fZnR0NCfbyefv0/79+xkdHfW+ncDv71Om0/d28v375ExVY70ApURvF71puds2NTVpCLZv3x53ghPr9CeERlXr9C2UTqBPHZ6PYz3KSEQKge8Bd6jqPy13+1AWyNm4cWPcCU6s058QGsE6fQul01WcRxkJ8A3gEVX9rON9chvlSX5+ftwJTqzTnxAawTp9C6XTVZyvEF4O3AS8QkQeSl9ec7Y7hLJATuZ96qSzTn9CaATr9C2UTlex7VRW1W4gjD/5jTHmeSCoM5VDWSCnpqYm7gQn1ulPCI1gnb6F0ukqqMntQlkgZ3Z2NohZEK3TnxAawTp9C6Uz8SemnY9Q5g3JHDOddNbpTwiNYJ2+hdLpKqgBwRhjTO4ENSCEskBOCHObgHX6FEIjWKdvoXS6Cmofgi2QY4wx525F7kM4fvx43AlOMnOmJJ11+hNCI1inb6F0ugpqQFhYWIg7wUkoJ9BZpz8hNIJ1+hZKp6ugBgRjjDG5E9Q+BDsPwS/r9CeERrBO30LpXJH7EDJzlyfd8PBw3AlOrNOfEBrBOn0LpdNVUANCKCumZRbqSDrr9CeERrBO30LpdBXUgGCMMSZ3ghoQQjkJpLm5Oe4EJ9bpTwiNYJ2+hdLpKqgBIZQd4KlUKu4EJ9bpTwiNYJ2+hdLpKqgB4eTJk3EnOMks7p101ulPCI1gnb6F0ukqqAHBGGNM7gQ1IBQVFcWd4KS2tjbuBCfW6U8IjWCdvoXS6SrWAUFE/k5ExkVkr8vtQ1kxra6uLu4EJ9bpTwiNYJ2+hdLpKu5XCLcB17ve2Ca388s6/QmhEazTt1A6XRXE+cNVdZeINMTZYIxJtlQKjh+HmRmYnYWTJ6PL4s8z10+dgrm5py+nX5+fjy6p1LM/Zj5fWIguqdQzPy7+XDX6ePToS7jooqevL/641CXzNXj63xZ/vvi6y8eMpQ7APJ+DMmMdEFyIyFZgK0B1dTU7duwAYMOGDZSVlTEwMABAZWUlmzZtYteuXQAUFBTQ1dVFf38/k5OTALS3tzM2Nsbhw4cBaGxspLi4mL17o3esqqqqaGpqoru7G4Di4mI6Ozvp6+vLLt/Z0dHByMgIo6OjAGzcuJH8/Hz27dsHRItul5SUZDtLSkro6Oigt7c3OzNiZ2cnw8PD2bMcm5ubSaVS2SMWamtrqaury/71UVpaSnt7Oz09PdnpO7q6uhgaGmJ8fByAlpYWZmdnOXDgAAD19fVUV1eTWT+ivLyctrY2uru7mZ+fB2DNmjU8/PDDHD16FIDW1lampqY4ePAgAA0NDaxdu5b+/n4AKioqaG1tZefOnagqIsKWLVsYGBjg2LFjALS1tTExMcGhQ4e8bae8vDyefPJJ79tp/fr12SUQn+t2mpmZoa+vLyfbafPmzQwODnrZTjMzM+zYsSMn22mp36crrmjinnt6+dWvipidLaG2toX+/mGefDLF9HQBa9bUMTo6w7//+ylmZvKBNZw4kcfERAezs3PMzuYzO+vvjQwRJT9fKSzMQyRFXt4CeXmwalUBMA+kyMtTVq0qApRU6hR5eUpxcQFFRQWcPDmDCBQW5rFmzRomJ/M4fvwpROCii8o5cWKG+fk5RKCsbA2pVIqTJ08gAqtXr6KkpJCpqUlElKKiQsrLyzl27CiqIALr1lUyNfVUdlaGiy56AXNzc8zMzCCirFmzhsLCAp566ikg2q9aXl7Ok08+iQiICOvWreNXvzrG3Nw8IkpFxVrS/9sv//jEfWx/+hXC3arastxtbYEcY5Jjehp+8Qs4eBBGR+HIEXjiiWd+HB+P/qo+kxe8ACoq4KKLoKwMSkthzZrocvrnJSXRpbgYVq1a+mNRERQWPn05/Xogiy565zq5XeJfISwWyj6Enp4eOjs7485YlnX6E0IjnHvn1BQMDkZP/I89Fn3MXMbGnnnb/HyoroaaGrj0Umhriz6/5BK4+GJYu/bpJ/+KimgwyM/30xmXUDpdBTUghLJATiizslqnPyE0wtk7JyZgzx7o73/6cuDA0+9Fi0BdHVxxBdxwQ/TxhS+MPtbVwbp1/v4CXwmPZ4hiHRBE5E7gWmCdiIwAH1fVb8TZZMzzQSoVPfn/+Mfw4IPRk396dwIAl18e/YX/jndAays0NsL69dFbM2blin0fwrkIZYGc+fl5CgqS/+LLOv0JofHQIfjhD1Pcf38+P/5x9IoAoif7tranL1dfDZWVsaYG8XhCOJ0rch9CKC/PhoaGgpgF0Tr9SWLjzAzcey/86EewbVv0vj/kc+ml8NrXwqteBdddF73vnzRJfDyXEkqnq6D2uYeyQE7mEMOks05/ktKYSkVP/u98Z/RE/6Y3we23w5VXwuc/D7fd9iAjI3DbbXDjjckcDCA5j+dyQul0FdQrBGPMs6nCwAB885tw553RIZ/l5fC2t8Fv/RZ0dUWHXwLs2BEdR2/MUoIaEEJZIKelZdlTKhLBOv2Jo3FkJPrr//bbo0NDCwvhNa+JdgTfcMPSO4BDeCzBOuMS1IAQyg7wUPZ1WKc/F7Lx5z+HW2+Fb387mmrh5S+Hv/1beMtblt8ZHMJjCdYZl6D2IYSyQE5mWoKks05/ct2oCvffD9dfHx0Getdd8L73RSeLdXfDe97jdmRQCI8lWGdcgnqFYMzzzfw8fO978Jd/GZ0rUF0Nn/oU/O7vRmf7GuNTUANCKAvk1NfXx53gxDr98d148iR8/evwV38VnT/Q1ARf/SrcdNNzOzkshMcSrDMuy75lJCJXiEhx+vNrReT3ReSinJctIZQFcqqTeizfaazTH1+NCwvwrW/Bi14E739/NCfQXXfBI4/A7/zOcz9TOITHEqwzLi77EL4HpETkhcA3gPXAt3JadQahTG4Xyoys1umPj8adO6GjIzo/oKIC7rsPfvITeMMb/M0RFMJjCdYZF5f/zRZUdR54I/A5Vf2vwCW5zTLm+ePRR+H1r4drr42mjP6Hf4Ddu+GVr4y7zDzfuAwIcyLyduCdwN3pf4vlvZv8M82VmzDl5eVxJzixTn/Op3F8HN77Xmhpge3b4dOfhqGhaD9BrubtD+GxBOuMy7KT24lIM/AeoEdV7xSR9cDbVPUzFyJwMVsgx6wEc3Pw2c9GRwvNzESHjH7sY1BVFXeZWalcJ7db9u8QVd2nqr+vqnemrw/HMRgA2eURky6ztGPSWac/ro0/+Uk0m+hHPgL/8T9GZxh/8YsXbjAI4bEE64zLGQ87FZHvqupbReRh4FkvI1T1JTktW0IoZypn1sJNOuv0Z7nGiYloEPja1+Cyy+D734+ml7jQQngswTrjcrbzED6Q/hjD/7bGrAyqcMcd8Ad/EA0KH/oQfOIT0TrBxiSN0z4EVd132r9dq6o7chm2lFD2ISwsLJAXwGre1unPUo1DQ/B7vxetStbRAV/5SjTtRJxCeCzBOn3ztg8B+K6I/LFESkTkb4BPP/fEc3fixIk4fuw5GxwcjDvBiXX6s7hxdhb+9E/hxS+Gvr5o4rl/+7f4BwMI47EE64yLy4DQAdQD/wb8DHgceLmPHy4i14vIfhF5TEQ+stztQ3m/7ujRo3EnOLFOfzKNP/1ptAzlxz8eLU7z6KPRUURJ+SMyhMcSrDMuTuchACeAEmAVMKyqC8/1B4tIPvAl4NVAM/D29CGuxgTnxIl8PvhB+LVfg6kpuOeeaLGampq4y4xx5zIg/IxoQPgPQBfRE/c/evjZLwUeU9WDqnoK+Dbw+rPdYfXq1R5+bO61JuG9AQfW6ce2bfCe9/wan/98tM9gcDBaqCaJkv5YZlhnPFxmO323qmb25B4BXi8iN3n42bXA4UXXR4jennoGEdkKbAWoqalhx44dAGzYsIGysjIGBgYAqKysZNOmTezatQuAgoICurq66O/vZ3JyEoD29nbGxsY4fDj6sY2NjRQXF7N3714AqqqqaGpqyh5bXFxcTGdnJ319fdlzIDo6OhgZGWF0dBSAjRs3kp+fz7590X73mpoaCgsLs10lJSV0dHTQ29ub3QfS2dnJ8PAwR44cAaC5uZlUKsX+/fujB6a2lrq6Onp7ewEoLS2lvb2dnp6e7IIcXV1dDA0NZdd0bWlpYXZ2Njs/e319PdXV1dm5VsrLy2lra6O7uzv71tv69esZGRnJvuxtbW1lamqKgwcPAtDQ0MDatWvp7+8HoKKigtbWVnbu3ImqIiJs2bKFgYEBjh07BkBbWxsTExMcOnTI23aqqKgglUp5307r16+np6fnvLdTaWk9X/jC5XzzmwXU1Z3ka187zG//9ou8b6fNmzczODjoZTuNjY1RVFSUk+3k8/fpoYceoqioyMt2yuXvU39/f3YGBZ/byffvkzNVdb4Aa4AbgXvO5X5n+F5vAb6+6PpNwN+c7T5NTU0agu3bt8ed4MQ6z98//qNqTY1qfr7qRz+qeu+9O+NOcpLEx3Ip1ukX0KcOz8su018XicgbROS7wBPAdcCX3YecMxoh2lmdUUe0w9qYxDp8GN74Rnjzm6Opqfv6oikoioqe8241Y2J3xgFBRF4lIn8HDANvBr4JTKjqu1T1+x5+9s+ARhFZLyJFwG8C/+tsdyguLvbwY3OvoaEh7gQn1ulufh7++q+huRnuvRf+4i+gtxeuuir6ehIaXVinX6F0ujrbPoR7gQeALlUdBhCRz/v6wao6LyLvS/+cfODvVPWsB/WGMtvp2rVr405wYp1ufvYz+C//BfbsiXYWf/GLsH79M28Td6Mr6/QrlE5XZ3vL6Brgp8B9IrJNRN5N9MTtjar+QFWbVPUKVf3UcrefmZnx+eNzJrPTKOms8+yeeipatayjA8bG4H/+T7j77mcPBmCPpW/WGY8zDgiqukdV/1hVrwA+AVwNFInIv6aP/DFmRVKNnvyvvBK+9CV43/uiJSzf/GYQibvOmNxxOn9SVX+iqu8jOlT0c0BnLqPOpKDA5SjZ+FVUVMSd4MQ6n+2RR+A3fgPe+la45BJ48EH4whdguXVQ7LH0yzrjsezkdkkSyuR2JjxjY9EspF/7WjQT6Sc/Gb0yCORvEGPOyufkdokxNTUVd4KTnTt3xp3gxDqjFcs+9Sl44Qvh61+PzjR+7DH44AfPbTCwx9Iv64zH2Q47/YGINFzAlhUjlFddz+fOVApuuw2amuBP/gRe9apoyokvfAEuvjgZjblgnX6F0unqbK8QbgN+JCK3iEjhBepZESSQPY/P185t26IZSd/1LqithQcegH/6p2hwOF/P18cyV6wzHmfdhyAia4CPAdcTnZiWPR1TVT+b87rT2D4Ec74WFuAHP4Bbb4Vdu6JDRz/96Wjn8Qr7nTbmWXztQ5gDjgPFQNlplwsulAVyMhNPJd3zofPUqeitoRe/GF77Whgehs99Ljqa6G1v8zcYPB8eywvJOuNxxt1mInI98Fmi6STaVDX2s8JCWSAnM1Nh0q3kzqeegq9+NXryf/xxeMlL4JvfjAaBwhy8AbqSH8s4WGc8znYcxS3AW5abTsKYJBkdhc9/Hr785Wihmle+Ev7+76OdxvbWkDFnF9R5CFdffbXu2bMn7oxlTU5OUr7cmUwJsFI6p6fhn/8Zbr892mEM0b6BP/qjaOdxEhqTwjr9CqVzRZ6HkEql4k5wMjExEXeCk5A75+fhhz+Ed7wDqqvhppui9Ytvvjk6j+DOOy/cYHCmxiSyTr9C6XQV1ICQWd0o6TKrGyVdaJ2qsHt3dNJYbS28+tXRkUM33RQdOnrwIPz5ny89+dyFakw66/QrlE5XdmK+SbSxMdi2rYrbboveDnr8cSgqio4Yesc7okEhkGUyjEm8oAaEUBbI2bBhQ9wJTpLYOTMTnSewbVt0efhhgGYqK6MdxL/+69GKZUmbUyyJj+VSrNOvUDpdBTUghLJATllZLKdpnLO4O+fnYf9+6O+PLrt3R6uQnToVvQro6opOHuvomGTLlnLyEvwGZ9yPpSvr9CuUTlcJ/hV7tlAWyAnlZJUL2Tk9HT3hZyaQ6+yMppRuaYH//J/hK1+JBoj3vz/aWXzsGPz4x/CRj4BIf6IHA7Bt7pt1xiOoVwgmuVThySfhF7+ILo899vTnv/hFtC8go7wcrr4a3vOe6EigtrZoHiGbatqYeMXyKygibyFahe1K4KWq6jRBUSgL5FRWVsad4GS5zoUFmJyM/lqfmIAjR56+PPHEsz9f/AJOBOrq4Ior4IYboo+NjdGi9Bs2cE5/8YfweIbQCNbpWyidrmI5MU1EriSaKO8rwIdcB4RQJrdbWFgg7wK9x6EKc3MwOwsnTz798fTPjx9/+jI9nfmoHD8uHD/+9BP/4stTT0XffykVFVBTE60qVlMTXS67LHriv+KK6NDPVav8/DdeyMfzfIXQCNbpWyidriemxfInt6o+Auc+dezw8Cn+23979pPU2a5nPl/q49k+d70sLDz74xNPjFNVVZO9nko98+Pp/5ZKRe+fL/64+PO5uehy6tTTn2euP5fpnQoKlNJSobQUysqiJ/lLLoHmZrjoouj64kvmib+62t+TvYtdu3Zx7bXXXrgfeB5CaATr9C2UTleJfw9GRLYCW6Nr1/Df/7um/z36l8wTeWaQzrziEQGRPFQXsrfNy5P01zV7PS9PWFhYyH6PvLw8FhZS6ftHb1MtLMxn71NUVMDCQgrVhfT1fPLyYH5+jry86Ego1RcgEs3MWlAAq1eXcOrUDLBAXp5SVraGublZUqm59PUS8vKUkydnyM9XSkuLKS1dxeTkBHl5yqpV+dTUVDIxMYbIPAUFyuWXX8r09ASzs9MUFi5w2WXV5OXN8dRTYxQVLVBTU0F19Qv45S+HKCxcYN26VbS3X8ng4IMUFp5i1aoUBQULrFu3jqNHjwLQ2trK1NQUBw8eBKChoYG1a9fS398PwKpVFVx+eSs7d+5EVRERtmzZwsDAQHaSr7a2NiYmJrIn7GzYsIGysrLszrfKyko2bdrErl270o9PAV1dXfT39zM5OQlAe3s7Y2NjHD58GIBTp07x5JNPsnfvXgCqqqpoamqiu7sbiA5H7uzspK+vj+npaQA6OjoYGRlhdHQUgI0bN5Kfn8++ffsAqKmpYf369fT09ABQUlJCR0cHvb292Vl1Ozs7GR4e5siRIwA0NzeTSqXYv38/ALW1tdTV1dHb28v09DR9fX20t7fT09OTPYmyq6uLoaEhxsfHAWhpaWF2dpYDBw4AUF9fT3V1NZlXvuXl5bS1tdHd3Z2dzHHz5s0MDg46b6eKigpaW5feTtPT0+zYsSMn26mxsZHi4mIv2ynT6Xs7AZSWlnrbTplO39vJ9++TM1XNyQW4D9i7xOX1i26zA2h3/Z4bN27UEDzwwANxJzixTn9CaFS1Tt9C6QT61OE5NtbJ7URkBytwH4IxxiTJipzcLpTzEDIvCZPOOv0JoRGs07dQOl3FMiCIyBtFZAToBO4RkXtd7hfKbKeZ9+6Szjr9CaERrNO3UDpdxXWU0V3AXXH8bGOMMUsLaoGctrY2DeEl2vT0NKWlpXFnLMs6/QmhEazTt1A6V+Q+hLm5ubgTnIwtnqchwazTnxAawTp9C6XTVVADwqlTp+JOcJI5LjvprNOfEBrBOn0LpdNVUAOCMcaY3AlqQFh1IedLeA4aGxvjTnBinf6E0AjW6Vsona6CGhDOde6juISyspt1+hNCI1inb6F0ugpqQMjMXZJ0mblcks46/QmhEazTt1A6XQU1IBhjjMmdoAaEwsLCuBOcVFVVxZ3gxDr9CaERrNO3UDpdBXVi2jXXXKO7d++OO2NZ8/PzQazuZp3+hNAI1ulbKJ0r8sS0zBzqSZeZ/z3prNOfEBrBOn0LpdNVUAOCMcaY3AlqQAhh7VII51A06/QnhEawTt9C6XQV1D4EWyDHGGPO3YrchxDKAjmhDFrW6U8IjWCdvoXS6SqoASGUBXJC2fltnf6E0AjW6Vsona6CGhCMMcbkTlD7EEJZIOfEiROUlJTEnbEs6/QnhEawTt9C6Uz0PgQRuVVEHhWRn4vIXSJykcv9QlkgZ2RkJO4EJ9bpTwiNYJ2+hdLpKq63jLYBLar6EmAIuNnlTqEskDM6Ohp3ghPr9CeERrBO30LpdBXLgKCqP1LV+fTVnwJ1cXQYY4x5Wuz7EETk+8B3VPX2M3x9K7AV4JJLLrnmW9/6FgAbNmygrKyMgYEBACorK9m0aRO7du0CoKCggK6uLvr7+5mcnASgvb2dsbGx7LJ3jY2NFBcXZ6ewraqqoqmpKXs6enFxMZ2dnfT19WWPJujo6GBkZCT7l8HGjRvJz89n3759ANTU1LB69WoOHjwIQElJCR0dHfT29man7+7s7GR4eJgjR44A0NzcTCqVYv/+/QDU1tZSV1dHb28vAKWlpbS3t9PT08Ps7CwAXV1dDA0NMT4+DkBLSwuzs7McOHAAgPr6eqqrq7OHxZWXl9PW1kZ3dzfz89FY3NTUxNGjRzl69CgAra2tTE1NZdsbGhpYu3Ytmf02FRUVtLa2snPnTlQVEWHLli0MDAxw7NgxANra2piYmODQoUPettO6deuoqanxvp3Wr19PT0+Pl+00NzdHRUVFTrbT5s2bGRwc9LKdxsfHKSwszMl28vn7NDAwQGFhofftBH5/n+6///7sCbM+t5Pv36eysjKnfQg5GxBE5D6gZokv3aKq/5K+zS1AO/AmdQi56qqr9KGHHvLamQvj4+NBzIJonf6E0AjW6VsonbHvVFbV61S1ZYlLZjB4J3ADcKPLYADhLJCT+Ss06azTnxAawTp9C6XTVSzztorI9cAfA1tUNYzTj40xZoWL6yijLwJlwDYReUhEvuxyp1AWyKmpWeqdsuSxTn9CaATr9C2UTlex71Q+F6EskDM7OxvELIjW6U8IjWCdvoXSGfs+hFwIZd6QzBERSWed/oTQCNbpWyidroIaEIwxxuROUANCKAvkhDC3CVinTyE0gnX6Fkqnq6D2IdgCOcYYc+5W5D6E48ePx53gJHNGZNJZpz8hNIJ1+hZKp6ugBoSFhYW4E5yEcgKddfoTQiNYp2+hdLoKakAwxhiTO0HtQ7DzEPyyTn9CaATr9C2UzhW5DyEzM2HSDQ8Px53gxDr9CaERrNO3UDpdBTUghLJiWmYa3qSzTn9CaATr9C2UTldBDQjGGGNyJ6gBIZSTQJqbm+NOcGKd/oTQCNbpWyidroIaEELZAZ5KpeJOcGKd/oTQCNbpWyidroIaEE6ePBl3gpPM0n1JZ53+hNAI1ulbKJ2ughoQjDHG5E5QA0JRUVHcCU5qa2vjTnBinf6E0AjW6Vsona6CGhBCWTGtrq4u7gQn1ulPCI1gnb6F0ukqqAHBJrfzyzr9CaERrNO3UDpdxTIgiMificjP0+sp/0hELo2jwxhjzNPieoVwq6q+RFWvAu4GPuZyp/z8/JxG+VJaWhp3ghPr9CeERrBO30LpdBX75HYicjNwmar+7nK3tQVyjDHm3CV+cjsR+ZSIHAZuxPEVQij7EEJZeNs6/QmhEazTt1A6XeXsFYKI3AfULPGlW1T1Xxbd7mZglap+/AzfZyuwFaCqquqa73znOwBs2LCBsrIyBgYGAKisrGTTpk3s2rULgIKCArq6uujv72dychKA9vZ2xsbGOHz4MACNjY0UFxezd+9e0t+fpqYmuru7ASguLqazs5O+vj6mp6cB6OjoYGRkhNHRUQA2btxIfn4++/btA6CmpobHH388u/5zSUkJHR0d9Pb2ZhfT6OzsZHh4ODsxVnNzM6lUKnuSS21tLXV1ddkdVqWlpbS3t9PT05Od8bWrq4uhoSHGx8cBaGlpYXZ2lgMHDgBQX19PdXU1mVdU5eXltLW10d3dzfz8PBCd+b1u3TqOHj0KQGtrK1NTUxw8eBCAhoYG1q5dS39/PwAVFRW0trayc+dOVBURYcuWLQwMDHDs2DEA2tramJiY4NChQ96206lTp2hra/O+ndavX5/9hX6u22l6epqampqcbKfNmzczODjoZTsdPnyY0tLSnGwnn79PDz74IKWlpd63E/j9fbr77ruzbxv53E6+f5/KysqcXiGgqrFegMuBvS63bWpq0hBs37497gQn1ulPCI2q1ulbKJ1Anzo8x8ayD0FEGlX1QPrz9wNbVPXNy90vlAVy5ufnKSgoiDtjWdbpTwiNYJ2+hdKZ9H0InxGRvSLyc+A/AR9wuVMoC+QMDQ3FneDEOv0JoRGs07dQOl3FMiCo6v+tqi0aHXr6WlUddblfKAvkZN6HTDrr9CeERrBO30LpdBXUmcrGGGNyJ6gBIZQFclpaWuJOcGKd/oTQCNbpWyidroIaEOLYAX4+QtnXYZ3+hNAI1ulbKJ2ughoQQlkgJ3PsctJZpz8hNIJ1+hZKp6ugBgRjjDG5E9SAEMoCOfX19XEnOLFOf0JoBOv0LZROV0ENCKEskFNdXR13ghPr9CeERrBO30LpdBXUgBDK5HahzMhqnf6E0AjW6Vsona6CGhCMMcbkTlADQigL5JSXl8ed4MQ6/QmhEazTt1A6XcW+QM65sAVyjDHm3CV9crvzkplDPeky878nnXX6E0IjWKdvoXS6CmpACOXVTGZhk6SzTn9CaATr9C2UTldBDQjGGGNyx/Yh5MDCwkJ2Cc0ks05/QmgE6/QtlM4VuQ8hs4Zq0g0ODsad4MQ6/QmhEazTt1A6XQU1IITyfl1mke2ks05/QmgE6/QtlE5XQQ0IxhhjcieoAWH16tVxJzhpbW2NO8GJdfoTQiNYp2+hdLqKdUAQkQ+JiIrIOpfbp1KpXCd5MTU1FXeCE+v0J4RGsE7fQul0FduAICL1wKuAX7reJ5TViQ4ePBh3ghPr9CeERrBO30LpdBXnK4S/Bj4MhHPcqzHGrGAFcfxQEXkdMKqqAyKy3G23AlvTV2dFZG+u+zxYBzwZd4QD6/QnhEawTt9C6dzocqOcnZgmIvcBNUt86Rbgo8B/UtWnROQQ0K6qyz6oItLncnJF3KzTrxA6Q2gE6/RtpXXm7BWCql631L+LyIuB9UDm1UEd0C8iL1XVI7nqMcYYc3YX/C0jVX0YqMpcP5dXCMYYY3InqPMQgK/GHeDIOv0KoTOERrBO31ZUZ1CT2xljjMmd0F4hGGOMyREbEIwxxgABDwjnOu3FhSYifyYiPxeRh0TkRyJyadxNpxORW0Xk0XTnXSJyUdxNSxGRt4jIoIgsiEjiDvETketFZL+IPCYiH4m7Zyki8nciMp7083hEpF5EtovII+lt/oG4m04nIqtE5EERGUg3fjLuprMRkXwR2SMidy932yAHhPOZ9iIGt6rqS1T1KuBu4GMx9yxlG9Ciqi8BhoCbY+45k73Am4BdcYecTkTygS8BrwaagbeLSHO8VUu6Dbg+7ggH88AfquqVwMuA9ybw8ZwFXqGqrcBVwPUi8rJ4k87qA8AjLjcMckAggGkvVHVy0dU1JLBVVX+kqplFJn5KdE5I4qjqI6q6P+6OM3gp8JiqHlTVU8C3gdfH3PQsqroLmIi7Yzmq+oSq9qc/nyJ6IquNt+qZNDKdvlqYviTu9xtAROqA3wC+7nL74AaExdNexN2yHBH5lIgcBm4kma8QFvt/gX+NOyJAtcDhRddHSNgTWKhEpAG4GuiNOeVZ0m/DPASMA9tUNXGNaZ8j+uN5weXGscxltByXaS8ubNHSztapqv+iqrcAt4jIzcD7gI9f0ECWb0zf5hail+p3XMi2xVw6E2qpybgS+ddiSESkFPge8MHTXm0ngqqmgKvS+93uEpEWVU3U/hkRuQEYV9XdInKty30SOSCEMu3FmTqX8C3gHmIYEJZrFJF3AjcAr9QYT0o5h8cyaUaA+kXX64DHY2pZEUSkkGgwuENV/ynunrNR1V+JyA6i/TOJGhCAlwOvE5HXAKuAchG5XVXfcaY7BPWWkao+rKpVqtqgqg1Ev4xtSZwDSUQaF119HfBoXC1nIiLXA38MvE5VZ+LuCdTPgEYRWS8iRcBvAv8r5qZgSfSX3jeAR1T1s3H3LEVELs4ckSciJcB1JPD3W1VvVtW69HPlbwL3n20wgMAGhMB8RkT2isjPid7iStzhc8AXgTJgW/rw2C/HHbQUEXmjiIwAncA9InJv3E0Z6Z3y7wPuJdoB+l1VHYy36tlE5E6gB9goIiMi8u64m87g5cBNwCvS/08+lP4LN0kuAbanf7d/RrQPYdlDOkNgU1cYY4wB7BWCMcaYNBsQjDHGADYgGGOMSbMBwRhjDGADgjHGmDQbEIxJS8+0OSwia9PXK9LXLz/D7d+YnnH3RQ7fu11EvuC72Rif7LBTYxYRkQ8DL1TVrSLyFeCQqn76DLf9LtEx6T9W1U9cwExjcsJeIRjzTH8NvExEPgh0AX+11I3Sc+28HHg30VmgmX9/o4jcJ5FLRGRIRGpE5NrMfPQismXRSVd7RKQs5/9VxjiwAcGYRVR1DvgjooHhg+kprZfyBuCHqjoETIhIW/r+dwFHgPcCXwM+vsTUKh8C3pteK+P/Ak74/u8w5nzYgGDMs70aeAJoOctt3k609gHpj29f9LX3Ey02NKuqdy5x358AnxWR3wcuWrQmhTGxSuRsp8bERUSuIlqN72VAt4h8W1WfOO02lcArgBYRUSAfUBH5cHrG2Fqi+eerRSRPVZ8xF72qfkZE7gFeA/xURK5T1cRNjmaef+wVgjFp6Zk2/5boraJfArcC/98SN30z8A+qenl65t16YBjoEpEC4O+B3yKa7O4Plvg5V6Rn7v0LoA9Y9iglYy4EGxCMedrvAL9U1W3p6/8DeJGIbDntdm8H7jrt375HNAh8FHhAVR8gGgx+W0SuPO22H0zPhDtAtP/AVqoziWCHnRpjjAHsFYIxxpg0GxCMMcYANiAYY4xJswHBGGMMYAOCMcaYNBsQjDHGADYgGGOMSfs/GTNB9VPtCUMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "##### Sigmoid\n",
    "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "x=np.linspace(-10,10,10)\n",
    "y=np.linspace(-10,10,100)\n",
    "fig = plt.figure()\n",
    "plt.plot(y,sigmoid(y),'b', label='linspace(-10,10,100)')\n",
    "plt.grid(linestyle='--')\n",
    "plt.xlabel('X Axis')\n",
    "plt.ylabel('Y Axis')\n",
    "plt.title('Sigmoid Function')\n",
    "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
    "plt.yticks([-2, -1, 0, 1, 2])\n",
    "plt.ylim(-2, 2)\n",
    "plt.xlim(-4, 4)\n",
    "plt.show()\n",
    "#plt.savefig('sigmoid.png')\n",
    "\n",
    "fig = plt.figure()\n",
    "##### TanH\n",
    "tanh = lambda x: 2*sigmoid(2*x)-1\n",
    "x=np.linspace(-10,10,10)\n",
    "y=np.linspace(-10,10,100)\n",
    "plt.plot(y,tanh(y),'b', label='linspace(-10,10,100)')\n",
    "plt.grid(linestyle='--')\n",
    "plt.xlabel('X Axis')\n",
    "plt.ylabel('Y Axis')\n",
    "plt.title('TanH Function')\n",
    "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
    "plt.yticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
    "plt.ylim(-4, 4)\n",
    "plt.xlim(-4, 4)\n",
    "plt.show()\n",
    "#plt.savefig('tanh.png')\n",
    "\n",
    "fig = plt.figure()\n",
    "##### ReLU\n",
    "relu = lambda x: np.where(x>=0, x, 0)\n",
    "x=np.linspace(-10,10,10)\n",
    "y=np.linspace(-10,10,1000)\n",
    "plt.plot(y,relu(y),'b', label='linspace(-10,10,100)')\n",
    "plt.grid(linestyle='--')\n",
    "plt.xlabel('X Axis')\n",
    "plt.ylabel('Y Axis')\n",
    "plt.title('ReLU')\n",
    "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
    "plt.yticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
    "plt.ylim(-4, 4)\n",
    "plt.xlim(-4, 4)\n",
    "plt.show()\n",
    "#plt.savefig('relu.png')\n",
    "\n",
    "fig = plt.figure()\n",
    "##### Leaky ReLU\n",
    "leakyrelu = lambda x: np.where(x>=0, x, 0.1*x)\n",
    "x=np.linspace(-10,10,10)\n",
    "y=np.linspace(-10,10,1000)\n",
    "plt.plot(y,leakyrelu(y),'b', label='linspace(-10,10,100)')\n",
    "plt.grid(linestyle='--')\n",
    "plt.xlabel('X Axis')\n",
    "plt.ylabel('Y Axis')\n",
    "plt.title('Leaky ReLU')\n",
    "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
    "plt.yticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
    "plt.ylim(-4, 4)\n",
    "plt.xlim(-4, 4)\n",
    "plt.show()\n",
    "#plt.savefig('lrelu.png')\n",
    "\n",
    "fig = plt.figure()\n",
    "##### Binary Step\n",
    "bstep = lambda x: np.where(x>=0, 1, 0)\n",
    "x=np.linspace(-10,10,10)\n",
    "y=np.linspace(-10,10,1000)\n",
    "plt.plot(y,bstep(y),'b', label='linspace(-10,10,100)')\n",
    "plt.grid(linestyle='--')\n",
    "plt.xlabel('X Axis')\n",
    "plt.ylabel('Y Axis')\n",
    "plt.title('Step Function')\n",
    "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
    "plt.yticks([-2, -1, 0, 1, 2])\n",
    "plt.ylim(-2, 2)\n",
    "plt.xlim(-4, 4)\n",
    "plt.show()\n",
    "#plt.savefig('step.png')\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 - Feed-Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "input_size = 784 # images are 28x28\n",
    "hidden_size = 500 # can try different classes\n",
    "num_classes = 10 # classes are 0-9\n",
    "num_epochs = 2 # can set to higher value if needed\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./pytorch/data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9913344it [00:01, 6501267.57it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./pytorch/data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./pytorch/data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./pytorch/data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29696it [00:00, 5945300.79it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./pytorch/data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./pytorch/data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./pytorch/data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1649664it [00:00, 2739982.28it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./pytorch/data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./pytorch/data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./pytorch/data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5120it [00:00, ?it/s]                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./pytorch/data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./pytorch/data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./pytorch/data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./pytorch/data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples = iter(test_loader) # convert to iter object\n",
    "example_data, example_targets = examples.next()\n",
    "print(example_data.shape, example_targets.shape) # 100 is batch size, 1 is number of colour channels, (28, 28) is image size\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(example_data[i][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        # no activation and no softmax at the end, just returning output\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss() # applies softmax\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [100/600], Loss: 0.3796\n",
      "Epoch [1/2], Step [200/600], Loss: 0.3489\n",
      "Epoch [1/2], Step [300/600], Loss: 0.1828\n",
      "Epoch [1/2], Step [400/600], Loss: 0.1773\n",
      "Epoch [1/2], Step [500/600], Loss: 0.1623\n",
      "Epoch [1/2], Step [600/600], Loss: 0.1476\n",
      "Epoch [2/2], Step [100/600], Loss: 0.1021\n",
      "Epoch [2/2], Step [200/600], Loss: 0.0845\n",
      "Epoch [2/2], Step [300/600], Loss: 0.1714\n",
      "Epoch [2/2], Step [400/600], Loss: 0.1022\n",
      "Epoch [2/2], Step [500/600], Loss: 0.1074\n",
      "Epoch [2/2], Step [600/600], Loss: 0.1672\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "n_total_steps = len(train_loader) \n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # origin shape: [100, 1, 28, 28]\n",
    "        # resized: [100, 784]\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96.85 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images) # test set of images with trained model\n",
    "        # max returns (value ,index) - index is the class label\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0) # number of samples in current batch\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13 - Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs have convolutional filters and pooling layers to learn features from images\n",
    "\n",
    "Filter kernels applied to images\n",
    "\n",
    "Max pooling used to downsample image by applying a maximum filter to subregions of the image, reduces computational cost and parameters needed to learn, reduces overfitting by providing an abstracted form of the input image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./maxpooling.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparameters \n",
    "num_epochs = 5 # accuracies for each class will be low with small number of epochs, increase this for higher accuracy\n",
    "batch_size = 4\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1091)>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m~\\miniconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1349\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[1;32m-> 1350\u001b[1;33m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[0;32m   1351\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1280\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1281\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1326\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1275\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1276\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    975\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    977\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1450\u001b[0m             self.sock = self._context.wrap_socket(self.sock,\n\u001b[1;32m-> 1451\u001b[1;33m                                                   server_hostname=server_hostname)\n\u001b[0m\u001b[0;32m   1452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m             \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m         )\n",
      "\u001b[1;32m~\\miniconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36m_create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m    869\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 870\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    871\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1138\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1091)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6260/429060561.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m train_dataset = torchvision.datasets.CIFAR10(root='./pytorch/data', train=True,\n\u001b[1;32m----> 9\u001b[1;33m                                         download=True, transform=transform)\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m test_dataset = torchvision.datasets.CIFAR10(root='./pytorch/data', train=False,\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torchvision\\datasets\\cifar.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torchvision\\datasets\\cifar.py\u001b[0m in \u001b[0;36mdownload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Files already downloaded and verified'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0mdownload_and_extract_archive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtgz_md5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torchvision\\datasets\\utils.py\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[1;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[0;32m    425\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m     \u001b[0mdownload_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[0marchive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torchvision\\datasets\\utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[1;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;31m# expand redirect chain if needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_redirect_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_hops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_redirect_hops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;31m# check if file is located on Google Drive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torchvision\\datasets\\utils.py\u001b[0m in \u001b[0;36m_get_redirect_url\u001b[1;34m(url, max_hops)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_hops\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0murl\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[1;32m--> 543\u001b[1;33m                                   '_open', req)\n\u001b[0m\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1392\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[1;32m-> 1393\u001b[1;33m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1395\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1350\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0;32m   1351\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1352\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1353\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1091)>"
     ]
    }
   ],
   "source": [
    "# dataset has PILImage images of range [0, 1]. \n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./pytorch/data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./pytorch/data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./cnn.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./conv_layer.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) # input channel size: 3 (images have 3 colour channels), output channel size: 6, kernel size: 5 (i.e. 5x5 kernel)\n",
    "        self.pool = nn.MaxPool2d(2, 2) # kernel size and stride (how many pixels shifted after each kernel operation) of 2\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) # input channel size must be equal to previous conv output channel size\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # final size after both conv and pooling layers are applied is 16x5x5 (5x5 image with 16 channels), need to flatten to 1D tensor hence input size is 16*5*5; can try different output size\n",
    "        self.fc2 = nn.Linear(120, 84) # can try number different to 84\n",
    "        self.fc3 = nn.Linear(84, 10) # 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14 - activation function doesn't change size \n",
    "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 5, 5\n",
    "        x = x.view(-1, 16 * 5 * 5)            # -> n, 400 - -1 will represent the number of samples in batch i.e. 4, as defined above\n",
    "        x = F.relu(self.fc1(x))               # -> n, 120\n",
    "        x = F.relu(self.fc2(x))               # -> n, 84\n",
    "        x = self.fc3(x)                       # -> n, 10 - no softmax, included in CrossEntropyLoss\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
    "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 2000 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print('Finished Training')\n",
    "PATH = './pytorch/cnn.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14 - Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model developed for one task is re-used as a starting point for another task - allows rapid generation of new models (training on new untrained models can take time)\n",
    "# Can be done by changing last layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./transfer.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.5, 0.5, 0.5])\n",
    "std = np.array([0.25, 0.25, 0.25])\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/hymenoptera_data' # has at least 'train' and 'val' folders, with folders for each class in them containing the datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=0) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Finetuning the convnet ####\n",
    "# Load a pretrained model and reset final fully connected layer.\n",
    "\n",
    "model = models.resnet18(pretrained=True) # resnet 18 CNN trained on > 1 mil images, can classify into 1000 object categories\n",
    "num_ftrs = model.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model.fc = nn.Linear(num_ftrs, 2) # new output layer\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StepLR Decays the learning rate of each parameter group by gamma every step_size epochs\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# Learning rate scheduling should be applied after optimizer’s update\n",
    "# e.g., you should write your code this way:\n",
    "# for epoch in range(100):\n",
    "#     train(...)\n",
    "#     validate(...)\n",
    "#     scheduler.step()\n",
    "\n",
    "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1) # every 7 epochs, learning rate is multiplied by gamma\n",
    "model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ConvNet as fixed feature extractor ####\n",
    "# Here, we want to freeze all the network except the final layer.\n",
    "# We need to set requires_grad == False to freeze the parameters so that the gradients are not computed in backward() \n",
    "# can make training faster by not training and calculating gradients of all layers, just the last one\n",
    "model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
    "model_conv = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15 - TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same code as 12 except for changes specfied below for TensorBoard\n",
    "\n",
    "############## TENSORBOARD ########################\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('./runs/mnist2') # change to wherever you want to store events for a particular dataset (name it whatever you want), then do in cmd \"tensorboard --logdir=PATH_TO_RUNS_FOLDER\"\n",
    "###################################################\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "input_size = 784 # 28x28\n",
    "hidden_size = 500 \n",
    "num_classes = 10\n",
    "num_epochs = 1\n",
    "batch_size = 64\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples = iter(test_loader)\n",
    "example_data, example_targets = examples.next()\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(example_data[i][0], cmap='gray')\n",
    "#plt.show()\n",
    "\n",
    "############## TENSORBOARD ########################\n",
    "img_grid = torchvision.utils.make_grid(example_data)\n",
    "writer.add_image('mnist_images', img_grid) # custom label provided for image grid\n",
    "\n",
    "#if using as .py script which has other stuff after this but you only want to test image loading for now\n",
    "#writer.close()\n",
    "#sys.exit()\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "############## TENSORBOARD ########################\n",
    "writer.add_graph(model, example_data.reshape(-1, 28*28)) # can give a batch as input\n",
    "#writer.close()\n",
    "#sys.exit()\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [100/938], Loss: 0.2115\n",
      "Epoch [1/1], Step [200/938], Loss: 0.1266\n",
      "Epoch [1/1], Step [300/938], Loss: 0.1666\n",
      "Epoch [1/1], Step [400/938], Loss: 0.2656\n",
      "Epoch [1/1], Step [500/938], Loss: 0.1251\n",
      "Epoch [1/1], Step [600/938], Loss: 0.2100\n",
      "Epoch [1/1], Step [700/938], Loss: 0.1034\n",
      "Epoch [1/1], Step [800/938], Loss: 0.3234\n",
      "Epoch [1/1], Step [900/938], Loss: 0.4483\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "running_loss = 0.0\n",
    "running_correct = 0 # running number of correct predictions\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # origin shape: [100, 1, 28, 28]\n",
    "        # resized: [100, 784]\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        running_correct += (predicted == labels).sum().item()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "            ############## TENSORBOARD ########################\n",
    "            writer.add_scalar('training loss', running_loss / 100, epoch * n_total_steps + i)\n",
    "            running_accuracy = running_correct / 100 / predicted.size(0)\n",
    "            writer.add_scalar('accuracy', running_accuracy, epoch * n_total_steps + i)\n",
    "            running_correct = 0\n",
    "            running_loss = 0.0\n",
    "            ###################################################\n",
    "\n",
    "# can see learning/loss curves and change parameters like learning rate to interactively optimise model (mnist1 has 0.001 LR, mnist2 has 0.01 LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 95.75 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "class_labels = []\n",
    "class_preds = []\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        values, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        class_probs_batch = [F.softmax(output, dim=0) for output in outputs] # turns output into probabilities between 0 and 1 - required for TensorBoard PR curve\n",
    "\n",
    "        class_preds.append(class_probs_batch)\n",
    "        class_labels.append(predicted)\n",
    "\n",
    "    # 10000, 10, and 10000, 1\n",
    "    # stack concatenates tensors along a new dimension\n",
    "    # cat concatenates tensors in the given dimension\n",
    "    class_preds = torch.cat([torch.stack(batch) for batch in class_preds])\n",
    "    class_labels = torch.cat(class_labels)\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')\n",
    "\n",
    "    ############## TENSORBOARD ########################\n",
    "    classes = range(10)\n",
    "    for i in classes:\n",
    "        labels_i = class_labels == i\n",
    "        preds_i = class_preds[:, i]\n",
    "        writer.add_pr_curve(str(i), labels_i, preds_i, global_step=0)\n",
    "        writer.close()\n",
    "    ###################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16 - Saving and Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 3 DIFFERENT METHODS TO REMEMBER:\n",
    " - torch.save(arg, PATH) # can be model, tensor, or dictionary\n",
    " - torch.load(PATH)\n",
    " - torch.load_state_dict(arg)\n",
    "'''\n",
    "\n",
    "''' 2 DIFFERENT WAYS OF SAVING\n",
    "# 1) lazy way: save whole model\n",
    "torch.save(model, PATH)\n",
    "\n",
    "# model class must be defined somewhere - data is bound to classes and directory structure\n",
    "model = torch.load(PATH)\n",
    "model.eval()\n",
    "\n",
    "# 2) recommended way: save only the state_dict and use later for inference if needed\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "# model must be created again with parameters\n",
    "model = Model(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "\n",
    "model = Model(n_input_features=6)\n",
    "# train your model...\n",
    "\n",
    "####################save all ######################################\n",
    "for param in model.parameters():\n",
    "    print(param)\n",
    "\n",
    "# save and load entire model\n",
    "FILE = \"model.pth\"\n",
    "torch.save(model, FILE)\n",
    "\n",
    "loaded_model = torch.load(FILE)\n",
    "loaded_model.eval()\n",
    "\n",
    "for param in loaded_model.parameters():\n",
    "    print(param)\n",
    "\n",
    "############save only state dict #########################\n",
    "# save only state dict\n",
    "FILE = \"model.pth\"\n",
    "torch.save(model.state_dict(), FILE)\n",
    "\n",
    "print(model.state_dict())\n",
    "loaded_model = Model(n_input_features=6)\n",
    "loaded_model.load_state_dict(torch.load(FILE)) # it takes the loaded dictionary, not the path file itself\n",
    "loaded_model.eval()\n",
    "print(loaded_model.state_dict())\n",
    "\n",
    "###########load checkpoint#####################\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "checkpoint = {\"epoch\": 90, \"model_state\": model.state_dict(), \"optim_state\": optimizer.state_dict()}\n",
    "print(optimizer.state_dict())\n",
    "FILE = \"checkpoint.pth\"\n",
    "torch.save(checkpoint, FILE)\n",
    "\n",
    "model = Model(n_input_features=6)\n",
    "optimizer = optimizer = torch.optim.SGD(model.parameters(), lr=0)\n",
    "\n",
    "checkpoint = torch.load(FILE)\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "optimizer.load_state_dict(checkpoint['optim_state'])\n",
    "epoch = checkpoint['epoch']\n",
    "\n",
    "model.eval() # or model.train()\n",
    "print(optimizer.state_dict())\n",
    "\n",
    "# Remember that you must call model.eval() to set dropout and batch normalization layers \n",
    "# to evaluation mode before running inference. Failing to do this will yield \n",
    "# inconsistent inference results. If you wish to resuming training, \n",
    "# call model.train() to ensure these layers are in training mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" SAVING ON GPU/CPU \n",
    "\n",
    "# 1) Save on GPU, Load on CPU\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = Model(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH, map_location=device))\n",
    "\n",
    "# 2) Save on GPU, Load on GPU\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "model = Model(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.to(device)\n",
    "\n",
    "# Note: Be sure to use the .to(torch.device('cuda')) function \n",
    "# on all model inputs, too!\n",
    "\n",
    "# 3) Save on CPU, Load on GPU\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = Model(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))  # Choose whatever GPU device number you want\n",
    "model.to(device)\n",
    "\n",
    "# This loads the model to a given GPU device. \n",
    "# Next, be sure to call model.to(torch.device('cuda')) to convert the model’s parameter tensors to CUDA tensors\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5b7aeff42ba6761a280498ade45e749cf5f5c1a448f52619a139fff18264354"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
